{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"lawdata Docs","text":"<p>Access and deploy a Datasette instance using litestream and docker. See lawdata.</p>"},{"location":"#config","title":"Config","text":""},{"location":"#datasette-query-files","title":"datasette-query-files","text":"<p>Unlike a default Datasette instance, canned SQL queries will not be found in <code>etc/metadata.yml</code>.</p> <p>The <code>datasette-query-files</code> plugin allows us to use a separate folder <code>/queries/</code> where each pairing of <code>.sql</code> and <code>.yml</code> becomes its own canned API endpoint.</p>"},{"location":"#native-sql-files","title":"Native .sql files","text":"<p>This setup makes it easier to write .sql files in VSCode with extensions (dbt formatter dependent on vscode-dbt):</p> JSON<pre><code>// settings.json\n\"files.associations\": {\n\"**/*.sql\": \"jinja-sql\",\n}\n</code></pre>"},{"location":"#relatively-complex-sql","title":"Relatively Complex SQL","text":"<p>The sqlite expressions are complex, making use of JSON1 and FTS5 extensions.</p>"},{"location":"#start-and-end-rows-precursor-to-fts5-snippet","title":"Start and End Rows, precursor to FTS5 snippet","text":"<p>Most of the queries utilize the following common table expression style:</p> SQL<pre><code>SELECT\nROW_NUMBER() over (ORDER BY cx.id) rn,\ncx.id row_idx,\nCOUNT(*) over () max_count\nFROM\nlex_tbl_codification_fts_units cx\nJOIN lex_tbl_codification_fts_units_fts\nON cx.rowid = lex_tbl_codification_fts_units_fts.rowid\nWHERE\ncx.codification_id = :code_id\nAND lex_tbl_codification_fts_units_fts match escape_fts(:q) -- escape_fts is a datasette-defined user function\n</code></pre> <p>This is an example of fetching the applicable rows for a given <code>code_id</code> with a matching full-text-search (fts) done on the <code>lex_tbl_codification_fts_units</code> table.</p> <p>It creates rows with the following fields under a designated order:</p> <ol> <li>row numbers <code>rn</code> for each matching row</li> <li>paired unique id <code>row_idx</code> corresponding to the <code>rn</code></li> <li>total number of rows <code>max_count</code></li> </ol> <p>Using this first CTE as the baseline, a second CTE will be used to filter the first CTE based on a <code>start_row</code> and an <code>end_row</code></p> SQL<pre><code>SELECT\nrn, row_idx, max_count\nFROM\nrowids_match_q\nWHERE\nrn BETWEEN CAST(:start AS INTEGER)\nAND CAST(:end AS INTEGER)\n</code></pre> <p>The reason for these preliminary CTEs is to limit the  rows that sqlite's fts5 snippet function will be called to operate on; if the snippet function were called in the first CTE, then all of the matching rows would have a computed value vs. the ranged rows limited by the <code>start</code> and <code>end</code> parameters.</p> SQL<pre><code>SELECT\nsnippet(\nlex_tbl_codification_fts_units_fts,\n0,\n'&lt;mark&gt;',\n'&lt;/mark&gt;',\n'...',\n15\n) matched_text\nFROM\nlex_tbl_codification_fts_units cx3\nJOIN lex_tbl_codification_fts_units_fts\nON lex_tbl_codification_fts_units_fts.rowid = cx3.rowid\nWHERE\ncx3.id = cx2.id -- cx2 is declared in the main SQL statement and will be based on the prefiltered rows\nAND lex_tbl_codification_fts_units_fts match escape_fts(:q)\n</code></pre> <p>The full SQL expression for this particular example can be found in <code>/queries/x/code_mp_fts_id.sql</code>.</p>"},{"location":"use/dev/","title":"Development Mode","text":""},{"location":"use/dev/#db-path","title":"db-path","text":"<ol> <li>A sqlite database is generated via corpus-x</li> <li>It can be accessed locally</li> <li>If not accessed locally, it can be restored from aws to local</li> </ol>"},{"location":"use/dev/#restore-db-from-aws-to-local","title":"Restore db from aws to local","text":"<p>If database cannot be found in the client device:</p> Bash<pre><code>export LITESTREAM_ACCESS_KEY_ID=xxx\nexport LITESTREAM_SECRET_ACCESS_KEY=yyy\nlitestream restore -if-db-not-exists -o x.db s3://corpus-x/db\n</code></pre>"},{"location":"use/dev/#configure-metadata","title":"Configure metadata","text":"<p>Edit the metadata.yml to allow access to the database without a token by commenting out:</p> YAML<pre><code>allow:\nbot_id: \"lex-bot\"\n</code></pre>"},{"location":"use/dev/#run-datasette","title":"Run Datasette","text":"<p>Assuming you've restored the database from aws or have a local file to a <code>&lt;db-path&gt;</code>, access the datasette instance:</p> Bash<pre><code>datasette \\\n--root \\\n-m etc/metadata.yml &lt;db-path&gt;\n</code></pre>"},{"location":"use/docker/","title":"Docker","text":"<p>A restored database can be accessed in a localhost container through a <code>datasette</code> instance via an authorization bearer token <code>LAWSQL_BOT_TOKEN</code>.</p>"},{"location":"use/docker/#assumptions","title":"Assumptions","text":"<ol> <li>A sqlite database is generated via corpus-x and replicated to aws.</li> <li>Credentials <code>LITESTREAM_ACCESS_KEY_ID</code> and <code>LITESTREAM_SECRET_ACCESS_KEY</code> are available to access aws.</li> <li><code>litestream</code> is installed to transfer the database to the docker container.</li> <li>Docker for Mac is installed, updated, and running.</li> <li>valid Dockerfile in root directory and the proper versions of the prerequisite apps are configured:<ol> <li><code>python</code>, 3.11</li> <li><code>litestream</code>, 0.39</li> <li><code>sqlite</code> 3.40</li> </ol> </li> <li>An updated <code>requirements.txt</code> file is generated that will be used by the Dockerfile</li> </ol>"},{"location":"use/docker/#setup-requirementstxt","title":"Setup requirements.txt","text":"Bash<pre><code>poetry export -f requirements.txt --output requirements.txt --without-hashes\n</code></pre>"},{"location":"use/docker/#dockerfile-to-docker-image","title":"Dockerfile to docker image","text":"<p>Can create the docker image with:</p> Bash<pre><code>docker build -t lawdata-local . # Will look for Dockerfile inside the . folder\n</code></pre> <p>This will start the build process. If successful, the docker image will be built and appear in the list of Docker Images found in VS Code's Docker extension.</p>"},{"location":"use/docker/#run-docker-image","title":"Run docker image","text":"<p>Run the docker image locally with:</p> Bash<pre><code>export LITESTREAM_ACCESS_KEY_ID=xxx\nexport LITESTREAM_SECRET_ACCESS_KEY=yyy\nexport LAWSQL_BOT_TOKEN=zzz\ndocker run \\\n-p 8080:8080 \\\n-e LITESTREAM_ACCESS_KEY_ID \\\n-e LITESTREAM_SECRET_ACCESS_KEY \\\n-e LAWSQL_BOT_TOKEN \\\nlawdata-local\n</code></pre>"},{"location":"use/docker/#restore-via-runsh","title":"Restore via run.sh","text":"<p>The Dockerfile terminates with <code>run.sh</code>.</p> <p>Since, on initialization, the sqlite database file doesn't exist yet, it will use litestream's <code>restore</code> command to copy the AWS variant to a local container.</p> Bash Session<pre><code>No database found, restoring from replica if exists\n2022/12/10 05:42:11.906021 s3: restoring snapshot xxx/00000000 to /db/x.db.tmp\n2022/12/10 05:43:45.299375 s3: restoring wal files: generation=xxx index=[00000000,00000000]\n2022/12/10 05:43:45.494176 s3: downloaded wal xxx/00000000 elapsed=191.820083ms\n2022/12/10 05:43:45.566760 s3: applied wal xxx/00000000 elapsed=73.156208ms\n2022/12/10 05:43:45.566865 s3: renaming database from temporary location\nINFO:     Started server process [15]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n</code></pre>"},{"location":"use/docker/#test-access-on-a-running-container","title":"Test access on a running container","text":"<p>Unauthorized:</p> Bash<pre><code>curl -IX get localhost:8080/x.json\n</code></pre> <p>Produces a HTTP/1.1  403 (FORBIDDEN) http status code:</p> Bash<pre><code>HTTP/1.1 403 Forbidden\ndate: x x x\nserver: uvicorn\ncontent-type: text/html; charset=utf-8\nTransfer-Encoding: chunked\n</code></pre> <p>Authorized:</p> <p>With xxx as <code>LAWSQL_BOT_TOKEN</code>, this results in a list of tables from restored the <code>x.db</code> via datasette + litestream:</p> Bash<pre><code>export token=&lt;whatever-value-of-LAWSQL_BOT_TOKEN&gt;\ncurl -H 'Authorization: Bearer ${token}' localhost:8080/x.json | jq\n</code></pre>"},{"location":"use/production/","title":"Production","text":""},{"location":"use/production/#initialization","title":"Initialization","text":"<p>Debug:</p> Bash<pre><code>fly doctor\nfly agent restart\n</code></pre>"},{"location":"use/production/#app-creation","title":"App creation","text":"<p>Check existing names then create the fly app with a unique name, we'll use as <code>lawdata</code>.</p> Bash<pre><code>fly apps create lawdata\n</code></pre>"},{"location":"use/production/#volume-creation","title":"Volume creation","text":"<p>After creating the app, create a volume that will be used by the app for persistent storage.</p> <p>Note that the app is separate from the volume.</p> <p>In case it already exists, it might be necessary to destroy the volume first and recreate it in case it has no more space.</p> Bash<pre><code>fly vol list\n# will display list of vol ids\nfly vol destroy &lt;instance-id&gt;\n# ? Are you sure you want to destroy this volume? Yes\n# Destroyed volume xxx from lawdata -- recall lawdata is the app name\n</code></pre> <p>We'll use the <code>db_lawdata</code> as the volume name to create, allocating 7GB as the volume size in the Singapore region with:</p> Bash<pre><code>fly vol create db_lawdata --region sin --size 7\nfly vol list\n</code></pre> <p>Review <code>fly.toml</code>:</p> <ol> <li><code>source</code> db_lawdata is created via <code>fly vol create db_lawdata</code>;</li> <li>the <code>destination</code> /data is prospective location of sqlite db; this is a folder of the volume that is described by the Dockerfile:</li> </ol> TOML<pre><code># fly.toml\n[mounts]\nsource = \"db_lawdata\"\ndestination = \"/data\"\n</code></pre> <p>See the associated Dockerfile:</p> Docker<pre><code># Dockerfile\nENV DB_FILE=/data/x.db\n</code></pre> <p>After the app is deployed, can ascertain the folder via</p> Bash<pre><code>fly ssh console\n# cd data\n# ls\n</code></pre> <p>The database file referred to is built with corpus-x.</p>"},{"location":"use/production/#setup-config","title":"Setup config","text":"<p>Review root <code>fly.toml</code>, specifically <code>app_name</code>, <code>mount.source</code>, and <code>services.internal_port</code></p> TOML<pre><code>app = \"lawdata\" # this was the name set during creation of the app\n[env]\nFLY_PRIMARY_REGION = \"sin\" # this is the region set during creation of the app's volume\n[mounts]\nsource = \"db_lawdata\" # this was the name set during creation of the app's volume; can verify this with fly volumes list\ndestination = \"/data\" # this is the folder to be created in the app for persistent storage, used in the Dockerfile\n[[services]]\ninternal_port = 8080 # will be used in the Dockerfile\n</code></pre>"},{"location":"use/production/#add-secrets","title":"Add secrets","text":"<p>Set the environment variables of the app:</p> Bash<pre><code>fly --app lawdata secrets import &lt; .env\n</code></pre>"},{"location":"use/production/#set-environment-vars","title":"Set environment vars","text":"<p>See <code>.env.example</code> which outlines 5 variables that serve the following purposes</p> vars purpose <code>LITESTREAM_ACCESS_KEY_ID</code> &amp; <code>LITESTREAM_SECRET_ACCESS_KEY</code> aws credentials for litestream.io to restore a replica of previously saved &amp; replicated database to the volume created <code>LAWSQL_BOT_TOKEN</code> Bearer Token, a user-made credential for datasette (see datasette-auth-tokens plugin), to query the database; see allow list in <code>metadata.yml</code> <code>DATASETTE_GITHUB_AUTH_CLIENT_ID</code> &amp; <code>DATASETTE_GITHUB_AUTH_CLIENT_SECRET</code> github credentials, see (datasette-auth-github plugin), to login and access datasette via the production url, set the callback url in <code>Github's / Developer Settings /</code> oAuth Apps"},{"location":"use/production/#build-local-image-then-deploy-to-fly","title":"build local image then deploy to fly","text":"<p>Use the local Dockerfile to build the image before deploying the same to fly.io</p> Bash<pre><code>fly deploy --local-only\n</code></pre> <p>This will result in the following lines:</p> Bash Session<pre><code>==&gt; Verifying app config\n--&gt; Verified app config\n==&gt; Building image\n==&gt; Creating build context\n--&gt; Creating build context done\n==&gt; Building image with Docker\n--&gt; docker host: 20.10.21 linux aarch64\n...\n</code></pre> <p>Substantive steps of the Dockerfile to create the Docker image</p> Step Description Time (seconds) 2 Building python slim with relevant libs ~120 5 Building sqlite with extensions ~420 7 Install requirements.txt ~60 <p>After the image is built, this will push the image to fly:</p> Bash Session<pre><code>--&gt; Building image done\n==&gt; Pushing image to fly\nThe push refers to repository [registry.fly.io/corpus-x]\n...\ndeployment-aaa: xxx\n--&gt; Pushing image done\nimage: registry.fly.io/corpus-x:deployment-aaa\nimage size: 323 MB\n==&gt; Creating release\n--&gt; release v2 created\n--&gt; You can detach the terminal anytime without stopping the deployment\n</code></pre>"},{"location":"use/production/#add-certificate-to-production-url","title":"Add certificate to production url","text":"<p>When the app is first created, the following URL will be usable: <code>lawdata.fly.dev</code></p> <p>After a certificate is issued, this can become <code>lawdata.xyz</code>.</p> Bash<pre><code>fly ips list\nfly certs create lawdata.xyz\n</code></pre> <p>Visit the fly.io dashboard and copy the <code>AAAA</code> value for <code>lawdata.fly.dev</code> to the domain's DNS settings.</p>"},{"location":"use/production/#test-access-on-deployed-app","title":"Test access on deployed app","text":""},{"location":"use/production/#unauthorized","title":"Unauthorized","text":"<p>Without token:</p> Bash<pre><code>curl -IX get https://lawdata.fly.dev/x\n</code></pre> <p>Produces a HTTP/2 403 (FORBIDDEN) http status code:</p> Bash<pre><code>HTTP/2 403\ndate: x x x x\nserver: Fly/x x x\ncontent-type: text/html; charset=utf-8\nvia: 2 fly.io\nfly-request-id: x x x-sin\n</code></pre>"},{"location":"use/production/#authorized","title":"Authorized","text":"<p>With the url set at: <code>lawdata.fly.dev</code>, the database file at <code>x.db</code>, and the secret previously set for <code>LAWSQL_BOT_TOKEN</code>, can test a json list of tables with:</p> Bash<pre><code>export token=&lt;whatever-value-of-LAWSQL_BOT_TOKEN&gt;\ncurl -H \"Authorization: Bearer ${token}\" https://corpus-x.fly.dev/x.json | jq\n</code></pre>"}]}